{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction from Text\n",
    "\n",
    "### Feature Extraction from Text with Scikit Learn\n",
    "\n",
    "In this notebook we are going to see how to find out the numeric feature vectors from text.\n",
    "\n",
    "We will discuss the following:\n",
    "\n",
    "##### Bag-of-Words (BoW)\n",
    "##### N-Gram\n",
    "**https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer**\n",
    "\n",
    "##### TF-IDF\n",
    "**https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words(BoW) based on Word-Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "\n",
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
      "\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Feature names - words\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "print()\n",
    "\n",
    "# Word-indicex in the vocabulary\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "print()\n",
    "\n",
    "# Numeric Vectors\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this is': 11, 'is the': 3, 'the first': 6, 'first document': 2, 'this document': 10, 'document is': 1, 'the second': 7, 'second document': 5, 'and this': 0, 'the third': 8, 'third one': 9, 'is this': 4, 'this the': 12}\n",
      "\n",
      "Dimension of the N-gram feature vector:  13\n",
      "\n",
      "[[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "\n",
    "X2 = vectorizer2.fit_transform(corpus)\n",
    "\n",
    "# Feature names\n",
    "#print(vectorizer2.get_feature_names())\n",
    "\n",
    "#print()\n",
    "\n",
    "# Word-indicex in the vocabulary\n",
    "print(vectorizer2.vocabulary_)\n",
    "\n",
    "print()\n",
    "print('Dimension of the N-gram feature vector: ',len(vectorizer2.get_feature_names()))\n",
    "\n",
    "print()\n",
    "# Numeric Vectors\n",
    "print(X2.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "#print(vectorizer.get_feature_names())\n",
    "print()\n",
    "\n",
    "# Word-indicex in the vocabulary\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      "  0.28108867 0.         0.28108867]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "# Numeric Vectors\n",
    "print(X.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
